{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Model\n",
    "---\n",
    "The aim of this assignment is to use hidden markov model for text-generation.\n",
    "\n",
    "**Dataset**: [Shakespeare's Plays](https://www.kaggle.com/kingburrito666/shakespeare-plays)\n",
    "\n",
    "__Strategy__:\n",
    "Following strategy is adopted to accomplish the main goal of this assignment:\n",
    "  - Dataset is loaded into pandas and cleaned; giving a list of all of the player-lines\n",
    "  - Markov model is built\n",
    "    - Each line is tokenized\n",
    "    - First-order and second-order markov chains are built based on tokens\n",
    "  - A function is written ```(write_line ())``` which, given a word hint, generates a full sentence based on the pre-built markov chains\n",
    "  - A play of given length is written; by randomly selecting starting words from Shakespeare's plays\n",
    "  \n",
    "In order to improve readability, the notebook is divided into sections based on the main task achieved in that section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section-1: Dataset Manipulation\n",
    "---\n",
    "The following main goals are achieved in this section:\n",
    "  - Dataset is loaded\n",
    "  - Uninteresting lines are deleted from the dataset\n",
    "  - Lines are converted into a list of string for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataline</th>\n",
       "      <th>Play</th>\n",
       "      <th>PlayerLinenumber</th>\n",
       "      <th>ActSceneLine</th>\n",
       "      <th>Player</th>\n",
       "      <th>PlayerLine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACT I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SCENE I. London. The palace.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enter KING HENRY, LORD JOHN OF LANCASTER, the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>So shaken as we are, so wan with care,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.2</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>Find we a time for frighted peace to pant,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataline      Play  PlayerLinenumber ActSceneLine         Player  \\\n",
       "0         1  Henry IV               NaN          NaN            NaN   \n",
       "1         2  Henry IV               NaN          NaN            NaN   \n",
       "2         3  Henry IV               NaN          NaN            NaN   \n",
       "3         4  Henry IV               1.0        1.1.1  KING HENRY IV   \n",
       "4         5  Henry IV               1.0        1.1.2  KING HENRY IV   \n",
       "\n",
       "                                          PlayerLine  \n",
       "0                                              ACT I  \n",
       "1                       SCENE I. London. The palace.  \n",
       "2  Enter KING HENRY, LORD JOHN OF LANCASTER, the ...  \n",
       "3             So shaken as we are, so wan with care,  \n",
       "4         Find we a time for frighted peace to pant,  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv ('../data/shakespeare.csv')\n",
    "df.head ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataline</th>\n",
       "      <th>Play</th>\n",
       "      <th>PlayerLinenumber</th>\n",
       "      <th>ActSceneLine</th>\n",
       "      <th>Player</th>\n",
       "      <th>PlayerLine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111390</th>\n",
       "      <td>111391</td>\n",
       "      <td>A Winters Tale</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5.3.179</td>\n",
       "      <td>LEONTES</td>\n",
       "      <td>Is troth-plight to your daughter. Good Paulina,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111391</th>\n",
       "      <td>111392</td>\n",
       "      <td>A Winters Tale</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5.3.180</td>\n",
       "      <td>LEONTES</td>\n",
       "      <td>Lead us from hence, where we may leisurely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111392</th>\n",
       "      <td>111393</td>\n",
       "      <td>A Winters Tale</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5.3.181</td>\n",
       "      <td>LEONTES</td>\n",
       "      <td>Each one demand an answer to his part</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111393</th>\n",
       "      <td>111394</td>\n",
       "      <td>A Winters Tale</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5.3.182</td>\n",
       "      <td>LEONTES</td>\n",
       "      <td>Perform'd in this wide gap of time since first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111394</th>\n",
       "      <td>111395</td>\n",
       "      <td>A Winters Tale</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5.3.183</td>\n",
       "      <td>LEONTES</td>\n",
       "      <td>We were dissever'd: hastily lead away.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dataline            Play  PlayerLinenumber ActSceneLine   Player  \\\n",
       "111390    111391  A Winters Tale              38.0      5.3.179  LEONTES   \n",
       "111391    111392  A Winters Tale              38.0      5.3.180  LEONTES   \n",
       "111392    111393  A Winters Tale              38.0      5.3.181  LEONTES   \n",
       "111393    111394  A Winters Tale              38.0      5.3.182  LEONTES   \n",
       "111394    111395  A Winters Tale              38.0      5.3.183  LEONTES   \n",
       "\n",
       "                                             PlayerLine  \n",
       "111390  Is troth-plight to your daughter. Good Paulina,  \n",
       "111391       Lead us from hence, where we may leisurely  \n",
       "111392            Each one demand an answer to his part  \n",
       "111393   Perform'd in this wide gap of time since first  \n",
       "111394           We were dissever'd: hastily lead away.  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep valid lines (i.e., spoken by a player) only\n",
    "df = df.dropna (subset = ['Player', 'ActSceneLine'])\n",
    "df.tail ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['So shaken as we are, so wan with care,', 'Find we a time for frighted peace to pant,', 'And breathe short-winded accents of new broils', 'To be commenced in strands afar remote.', 'No more the thirsty entrance of this soil']\n"
     ]
    }
   ],
   "source": [
    "lines = df ['PlayerLine'].tolist ()\n",
    "print lines [:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section-2: Hidden Markov Model\n",
    "---\n",
    "This section provides helper functions for building the hidden markov model on a text corpus. It is further divided into sub-section to increase modularity.\n",
    "\n",
    "### Section-2.1: Declare Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The length of lines generated based on HMM is restricted to this value.\n",
    "# It is a safeguard to protect the code from a potential infinite loop\n",
    "MAX_LINE_LENGTH = 20\n",
    "\n",
    "# This is used to check the equality of two floating point values. If\n",
    "# their difference is less than this value, they are considered equal \n",
    "FLOAT_DELTA = 0.0001\n",
    "\n",
    "# This special string is used to mark the end of a sentence\n",
    "END_TOKEN = 'endl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section-2.2: Helper Functions for Text-Parsing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove white-spaces and punctuations from a line and convert it\n",
    "# into a list of tokens\n",
    "def tokenize (line):\n",
    "    baseline = line.strip ().lower ()\n",
    "    tokens = ''.join ([x for x in baseline if x not in string.punctuation]).split ()\n",
    "    return tokens\n",
    "\n",
    "# Add a pairing to dictionary\n",
    "def insert_link (dictionary, key, value, debug = False):\n",
    "    if key not in dictionary:\n",
    "        dictionary [key] = []\n",
    "    if debug: print key, dictionary [key]\n",
    "    dictionary [key].append (value)\n",
    "    \n",
    "# Convert list to probability values\n",
    "def to_probability (chain):\n",
    "    frequencies = {}\n",
    "    probabilities = {}\n",
    "    num_of_words = len (chain)\n",
    "    \n",
    "    for word in chain:\n",
    "        frequencies [word] = frequencies.get (word, 0) + 1\n",
    "    \n",
    "    for word, frequency in frequencies.items ():\n",
    "        probabilities [word] = round (float (frequency) / num_of_words, 3)\n",
    "    \n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section-2.3: Main Function for Building the Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_markov_model (corpus, first_order_markov_chain, second_order_markov_chain):\n",
    "    # This is a dictionary of words which have been used to\n",
    "    # start a line in Shakespeare's plays\n",
    "    words = []\n",
    "\n",
    "    for line in corpus:\n",
    "        tokens = tokenize (line)\n",
    "        num_of_tokens = len (tokens)\n",
    "        \n",
    "        for idx in xrange (num_of_tokens):\n",
    "            token = tokens [idx]\n",
    "            \n",
    "            if idx == 0:\n",
    "                words.append (token)\n",
    "                \n",
    "                # We are not interested in the first word of a\n",
    "                # line since nothing precedes it\n",
    "                continue\n",
    "                \n",
    "            # Populate first-order markov chain           \n",
    "            last_token = tokens [idx - 1]\n",
    "            insert_link (first_order_markov_chain, last_token, token)\n",
    "            \n",
    "            # The second word in a line can only have a first-level\n",
    "            # markov chain since there is only a single word before it\n",
    "            if idx == 1:\n",
    "                continue\n",
    "    \n",
    "            # The last pair of word of a line is special. We want\n",
    "            # to chain it with 'END'; to help in finishing a line\n",
    "            # during predicitions\n",
    "            if idx == num_of_tokens - 1:\n",
    "                insert_link (second_order_markov_chain, (last_token, token), END_TOKEN)\n",
    "        \n",
    "            # Populate second-order markov chain\n",
    "            second_last_token = tokens [idx - 2]\n",
    "            insert_link (second_order_markov_chain, (second_last_token, last_token), token)\n",
    "    \n",
    "    # Convert first-order markov chain to probability values\n",
    "    for word, chain in first_order_markov_chain.items ():\n",
    "        first_order_markov_chain [word] = to_probability (chain)\n",
    "\n",
    "    # Convert first-order markov chain to probability values\n",
    "    for pair, chain in second_order_markov_chain.items ():\n",
    "        second_order_markov_chain [pair] = to_probability (chain)\n",
    "    \n",
    "    print '[STATUS] Successfully built Markov Model on Corpus!\\n'\n",
    "    return list (set (words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section-2.4: Helpers Functions for using the Markov Model for Text-Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pick next word from the second-order markov chain. It should be the\n",
    "# highest probability one. If multiple such words exist, randomly pick one\n",
    "def predict_next_word (key, dictionary, debug = False):\n",
    "    max_probability = 0.0\n",
    "    most_probable_words = []\n",
    "    \n",
    "    for next_word, probability in dictionary.items ():\n",
    "        if probability > max_probability:\n",
    "            max_probability = probability\n",
    "            most_probable_words = [next_word]\n",
    "        elif max_probability - probability < FLOAT_DELTA:\n",
    "            most_probable_words.append (next_word)\n",
    "    \n",
    "    if debug: print key, most_probable_words\n",
    "    return random.choice (most_probable_words)\n",
    "\n",
    "# Randomly pick a word that can follow; from the first-order markov chain\n",
    "def pick_next_word (key, dictionary, debug = False):\n",
    "    if debug: print dictionary\n",
    "    return random.choice (dictionary.keys ())\n",
    "\n",
    "# Generate text based on corpus\n",
    "def write_line (start_word, markov_chain_one, markov_chain_two):\n",
    "    line = []\n",
    "    word = start_word.lower ()\n",
    "    \n",
    "    if word not in markov_chain_one.keys ():\n",
    "        print '[FATAL] Word could not be found in corpus. Please reselect!'\n",
    "        return\n",
    "    \n",
    "    line.append (word)\n",
    "    next_word = pick_next_word (start_word, markov_chain_one [start_word])\n",
    "    line.append (next_word)\n",
    "    \n",
    "    n = 0\n",
    "    while n < MAX_LINE_LENGTH:\n",
    "        next_next_word = predict_next_word ((word, next_word), markov_chain_two [(word, next_word)])\n",
    "        \n",
    "        if next_next_word == END_TOKEN:\n",
    "            return ' '.join (line)\n",
    "        \n",
    "        word = next_word\n",
    "        next_word = next_next_word\n",
    "        line.append (next_next_word)\n",
    "        n += 1\n",
    "\n",
    "# Write a Shakespeare play of given length\n",
    "def write_play (hints, mc1, mc2):\n",
    "    for word in hints:\n",
    "        print write_line (word, mc1, mc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section-3: Demonstration\n",
    "---\n",
    "In this section, the hidden markov model developed herein is used for text-generation. For this purpose, a play of given length is written to demonstrate the correctness as well as extent and limitation of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] Successfully built Markov Model on Corpus!\n",
      "CPU times: user 6.48 s, sys: 181 ms, total: 6.66 s\n",
      "Wall time: 6.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# This is the first order markov chain. It chains a word\n",
    "# with the word(s) that can come after it\n",
    "mc_odr1 = {}\n",
    "\n",
    "# This is the second order markov chain. It chains a pair\n",
    "# of words with word(s) that can follow it\n",
    "mc_odr2 = {}\n",
    "\n",
    "words = build_markov_model (lines, mc_odr1, mc_odr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shook hands nor bade farewell to your majesty\n",
      "seeing him i will not be\n",
      "odours savours sweet\n",
      "swallowed the whole world\n",
      "roger earl of march\n",
      "only commendable\n",
      "goodly ilion stand\n",
      "top go to\n",
      "quarrels may be\n",
      "figured quite oer with burning meteors\n",
      "burthen cromwell tis a good\n",
      "starting thence away\n",
      "musings but i will not be\n",
      "unreverent shoulders\n",
      "willd it\n",
      "implore secrecythat the king\n",
      "measure your lubbers\n",
      "hit three times today my lord\n",
      "silvius had they what they do\n",
      "sheriff with a\n"
     ]
    }
   ],
   "source": [
    "play_length = 20\n",
    "hints = [random.choice (words) for x in range (play_length)]\n",
    "write_play (hints, mc_odr1, mc_odr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section-4: Conclusion\n",
    "---\n",
    "It seems that the text-generation with Markov Model is working reasonably well.\n",
    "\n",
    "---\n",
    "**ACKNOWLEDGEMENT**: Following source has been used to understand the principles of text-generation using HMM:\n",
    "  - [Reference](https://medium.com/ymedialabs-innovation/next-word-prediction-using-markov-model-570fc0475f96)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
